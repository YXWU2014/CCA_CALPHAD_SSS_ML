{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch evaluate ML-based properties for the composition datesets used for CALPHAD\n",
    "\n",
    "**Author:** Y.X. Wu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "notebook_fname = \"NN_full_RepeatedKFold_v3_BO_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../CCA_representation_ML/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(f'cpu_count: {os.cpu_count()}')\n",
    "\n",
    "# Data Path\n",
    "data_path = '../CCA_representation_ML/01_Dataset_Cleaned/'\n",
    "if os.path.isfile(data_path+'LiteratureDataset_Corrosion_YW_v3_processed.xlsx'):\n",
    "    print(f\"Folder '{data_path}' found.\")\n",
    "else:\n",
    "    print(f\"Warning: File '{data_path}' not found!\")\n",
    "\n",
    "# Model Path\n",
    "model_path = '../CCA_representation_ML/04_Model_Saved/'\n",
    "model_path_bo = f'{model_path}{notebook_fname}/'\n",
    "\n",
    "# Use GPU or not\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print('not using GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2260f167",
   "metadata": {},
   "source": [
    "### Check the model and scalers\n",
    "\n",
    "- Show the model.h5 files in this directory\n",
    "- Load scalers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.postprocessing_evalutation import display_saved_models\n",
    "\n",
    "display_saved_models(model_path_bo)\n",
    "\n",
    "# Load the scalers dictionary from a file using pickle\n",
    "with open(data_path + 'scalers.pkl', 'rb') as f:\n",
    "    scalers = pickle.load(f)\n",
    "    print(\"\")\n",
    "print(scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict based on new data inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates for PVD alloy representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the wafer-coordinates\n",
    "df_PVD_x_y = pd.read_excel(data_path + 'PVD_x_y.xlsx')\n",
    "coord_x = df_PVD_x_y[\"x\"].to_numpy(dtype=float)\n",
    "coord_y = df_PVD_x_y[\"y\"].to_numpy(dtype=float)\n",
    "index_PVD_x_y = df_PVD_x_y.index.values+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up compositional input for new alloys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "Flag_Calc_KW = False\n",
    "Flag_Calc_All = True\n",
    "\n",
    "if Flag_Calc_KW:\n",
    "    data_path_compo = './v6_A-B-C-D-E_Sputtering_ML_Exp/'\n",
    "\n",
    "    compo_A_B_C_D_E_list = [['Ni', 'Cr', 'Co', 'V', 'Fe'],\n",
    "                            ['Ni', 'Cr', 'Mo', 'Ti', 'Fe']]\n",
    "    compo_A_B_C_D_E_fname_list = ['KW99', 'KW131']\n",
    "\n",
    "\n",
    "elif Flag_Calc_All:\n",
    "    data_path_compo = './v6_A-B-C-D-E_Sputtering_ML_All/'\n",
    "\n",
    "    # Define the set of elements for D and E\n",
    "    set_D_E = [{'Co'}, {'V'}, {'Mn'}, {'Mo'}, {'Cu'},\n",
    "               {'Nb'}, {'W'}, {'Ti'}, {'Al'}, {'Si'}, {'Ta'}]\n",
    "\n",
    "    # Generate all possible combinations of D and E\n",
    "    compo_D_E_list = list(combinations(set_D_E, 2))\n",
    "\n",
    "    compo_A_B_C_D_E_list = []\n",
    "    compo_A_B_C_D_E_fname_list = []\n",
    "    for compo_D_E in compo_D_E_list:\n",
    "        # Convert the current combination to a list and flatten it\n",
    "        compo_D_E_list = [item for sublist in compo_D_E for item in sublist]\n",
    "\n",
    "        # Define the current combination of A, B, C, D, E\n",
    "        compo_A_B_C_D_E = ['Fe', 'Cr', 'Ni'] + compo_D_E_list\n",
    "        compo_A_B_C_D_E_merge = '_'.join([*compo_A_B_C_D_E])\n",
    "\n",
    "        compo_A_B_C_D_E_list.append(compo_A_B_C_D_E)\n",
    "        compo_A_B_C_D_E_fname_list.append(compo_A_B_C_D_E_merge)\n",
    "\n",
    "    print(compo_A_B_C_D_E_list[0])\n",
    "    print(compo_A_B_C_D_E_fname_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions for new alloys\n",
    "\n",
    "`read_new_data_feature_calc` can calcualte the engineered features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.postprocessing_prediction import read_new_data_feature_calc, predict_bootstrap_NNH_NNC, plot_prediction_uncertainty, plot_prediction_uncertainty_AVG\n",
    "from tqdm import tqdm\n",
    "\n",
    "for compo_A_B_C_D_E, compo_A_B_C_D_E_fname in tqdm(zip(compo_A_B_C_D_E_list, compo_A_B_C_D_E_fname_list), desc='Processing', total=len(compo_A_B_C_D_E_list)):\n",
    "\n",
    "    print(compo_A_B_C_D_E)\n",
    "    print(compo_A_B_C_D_E_fname)\n",
    "    vars_ele, KW_name = compo_A_B_C_D_E, compo_A_B_C_D_E_fname\n",
    "\n",
    "    file_name_input = f'{data_path_compo}v6_{KW_name}_SSS_FCC_byCompo_wt_pct.xlsx'\n",
    "    df_new_wt = pd.read_excel(file_name_input)\n",
    "\n",
    "    compo_new, HC_specific_features, C_specific_testing = read_new_data_feature_calc(df_new_wt, vars_ele,\n",
    "                                                                                     specific_features_sel_column=['delta_a', 'Tm', 'sigma_Tm',\n",
    "                                                                                                                   'Hmix', 'sigma_Hmix', 'sigma_elec_nega', 'VEC', 'sigma_VEC'],\n",
    "                                                                                     C_testing=np.array([25, 1, 7, 0.333]))\n",
    "\n",
    "    NNH_model_name = 'NNH_model_RepeatedKFold_{}.h5'\n",
    "    NNC_model_name = 'NNC_model_RepeatedKFold_{}.h5'\n",
    "    k_folds, n_CVrepeats, mc_repeat = 6, 2, 100\n",
    "\n",
    "    (H1_new_pred_stack, H1_new_pred_mean, H1_new_pred_std,\n",
    "     C2_new_pred_stack, C2_new_pred_mean, C2_new_pred_std) = predict_bootstrap_NNH_NNC(\n",
    "        model_path_bo, NNH_model_name, NNC_model_name,\n",
    "        compo_new, HC_specific_features, C_specific_testing,\n",
    "        scalers, k_folds, n_CVrepeats, mc_repeat)\n",
    "\n",
    "    # Concatenate and compute mean and std + save to excel\n",
    "    H1_new_pred_KFold_mean = np.mean(np.concatenate(\n",
    "        H1_new_pred_stack, axis=0), axis=0).reshape(-1)\n",
    "    H1_new_pred_KFold_std = np.std(np.concatenate(\n",
    "        H1_new_pred_stack, axis=0), axis=0).reshape(-1)\n",
    "    C2_new_pred_KFold_mean = np.mean(np.concatenate(\n",
    "        C2_new_pred_stack, axis=0), axis=0).reshape(-1)\n",
    "    C2_new_pred_KFold_std = np.std(np.concatenate(\n",
    "        C2_new_pred_stack, axis=0), axis=0).reshape(-1)\n",
    "\n",
    "    df_new_wt['H1_new_pred_KFold_mean'] = H1_new_pred_KFold_mean\n",
    "    df_new_wt['H1_new_pred_KFold_std'] = H1_new_pred_KFold_std\n",
    "    df_new_wt['C2_new_pred_KFold_mean'] = C2_new_pred_KFold_mean\n",
    "    df_new_wt['C2_new_pred_KFold_std'] = C2_new_pred_KFold_std\n",
    "\n",
    "    file_name_output = f'{data_path_compo}v6_{KW_name}_SSS_FCC_byCompo_wt_pct_ML.xlsx'\n",
    "    display(df_new_wt.head(3))\n",
    "    df_new_wt.to_excel(file_name_output, index=False)\n",
    "\n",
    "    if Flag_Calc_KW:\n",
    "        # NNH predictions\n",
    "        plot_prediction_uncertainty(data_path_compo, coord_x, coord_y, index_PVD_x_y, H1_new_pred_mean, H1_new_pred_std,\n",
    "                                    pred_label='Hardness', unc_label='Hardness uncertainty',\n",
    "                                    title='NNH_RepeatedKFold_prediction_uncertainty_eachFold_' + KW_name,\n",
    "                                    vmin1=100, vmax1=300,\n",
    "                                    vmin2=25, vmax2=100)\n",
    "\n",
    "        # NNC predictions\n",
    "        plot_prediction_uncertainty(data_path_compo, coord_x, coord_y, index_PVD_x_y, C2_new_pred_mean, C2_new_pred_std,\n",
    "                                    pred_label='Pitting potential (mV)', unc_label='Pitting potential uncertainty (mV)',\n",
    "                                    title='NNC_RepeatedKFold_prediction_uncertainty_eachFold_' + KW_name,\n",
    "                                    vmin1=0, vmax1=900,\n",
    "                                    vmin2=50, vmax2=150)\n",
    "\n",
    "        # NNH_NNC_AVG predictions\n",
    "        plot_prediction_uncertainty_AVG(data_path_compo, coord_x, coord_y, index_PVD_x_y, H1_new_pred_stack, C2_new_pred_stack,\n",
    "                                        title='NNH_NNC_RepeatedKFold_prediction_uncertainty_AVG_' + KW_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bb1e37c70b1d2984796c5ff5b7458aa397f7ffd0c82b990a87aa0f6b2cdb3f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
